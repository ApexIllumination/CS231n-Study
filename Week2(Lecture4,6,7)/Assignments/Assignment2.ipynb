{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0-BTu3kNW-L",
        "outputId": "1a4744a9-307f-459f-f522-acf211adf2ff"
      },
      "outputs": [],
      "source": [
        "# PyTorch 설치\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NYK1mocKpr8",
        "outputId": "3d5c7d4f-0d09-4e88-8506-4e9ed5217beb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# CIFAR-10 데이터셋 다운로드 및 변환\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=4, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform\n",
        ")\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=4, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "classes = (\n",
        "    'plane', 'car', 'bird', 'cat',\n",
        "    'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
        ")\n",
        "\n",
        "# Two-Layer Neural Network 정의\n",
        "class TwoLayerNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwoLayerNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(3 * 32 * 32, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3 * 32 * 32)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 모델, 손실 함수, 최적화기 초기화\n",
        "net = TwoLayerNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 모델 학습\n",
        "for epoch in range(10):  # 데이터셋을 여러 번 반복합니다.\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # 변화도(gradient) 매개변수를 0으로 초기화\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파 + 역전파 + 최적화\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 통계 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # 미니배치마다 출력\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('학습 종료')\n",
        "\n",
        "# 모델 저장\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "# 학습된 모델을 시험 데이터셋에서 테스트\n",
        "net = TwoLayerNN()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'네트워크의 정확도: {100 * correct / total:.2f}%')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XIR-g-28PfnG"
      },
      "source": [
        "하이퍼파라미터를 조정해보세요. learning rate, batch Size 수정 등을 통해 정확도를 높일 수 있습니다.\n",
        "\n",
        "\n",
        "학습률을 높이면 빠르게 수렴하지만 발산할 수 있고, 낮추면 안정적으로 학습할 수 있지만 학습 시간이 길어질 수 있습니다.\n",
        "더 큰 미니배치 크기를 사용하면 학습 속도가 빨라질 수 있지만 메모리 사용량이 늘어날 수 있습니다. 작은 미니배치 크기를 사용하면 모델이 더 안정적으로 학습될 수 있지만 학습 시간이 길어질 수 있습니다.\n",
        "\n",
        "정규화 기법인 배치 정규화(Batch Normalization) 또는 드롭아웃(Dropout)을 사용하여 과적합을 줄일 수 있습니다.\n",
        "\n",
        "다양한 옵티마이저 시도하여 학습을 시도할 수 있습니다. SGD, Adam, RMSprop 등을 시도해보세요.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
